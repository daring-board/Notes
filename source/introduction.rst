.. _introduction:

  .. toctree::
    :maxdepth: 4

序論
=============
| 学問としてのコンピュータサイエンスは1960年代に始まった。主にプログラミング言語や
| コンパイラ、OS(オペレーティングシステム)、そして、数学的な理論がこの分野支えてきた。
| 理論的なコンピュータサイエンスコースでは有限オートマトン、正規表現、文脈自由言語、
| 計算可能性を扱ってきた。1970年代には、アルゴリズムが重要な理論として扱われるように
| なった。この頃のコンピュータサイエンスの主な目的はコンピュータを便利にすることで
| あった。現在は根本的な変化が起こり、アプリケーションを充足させることに注目するように
| なっている。この変化には多数の理由がある。コンピュータ化とコミュニケーションの融合は
| 重要な役割を果たしてきた。自然科学、商業、その他の分野で強化された観測機能、収集機能、
| 保存機能を使用するには、データに対する理解と現代の環境でデータを処理する方法を変更し
| ていく必要がある。日常生活の中心的な側面としてのウェブおよびSNSの出現は理論の機会と課
| 題の両方を表現している。

| コンピュータサイエンスの伝統的な分野は非常に重要な分野として残っている。コンピュータを
| 使って、アプリケーションから出力される大量のデータから使用可能な情報を抽出し、それを
| 理解することに関与していく研究者は増えていくだろう。それはうまく定義された特定の問題の上
| でコンピュータを便利にしていくことにとどまらない。この信念の元で、ちょうどオートマトン
| の理論やアルゴリズム、その他の関連するトピックの理解によって過去40年間の学生たちが有利
| になったように、今後40年間役に立つと予想される理論を扱うこの本を出版した。主な変更
| 点は確率論と統計、数値計算法の重要性の増加である。

| この本の初期草案は学部、大学院の両方のコースで使用されています。学部コース要求される背
| 景的な資料は付録に載せています。そのため、付録中には宿題用の問題を含めています。

| 情報処理技術、研究、機械学習のような多様な分野の現代のデータは、多くのコンポーネントを
| を持つベクトルとしてよく表現されます。そのベクトルは多数の属性を持つようなデータを保持
| するための記録装置ではありません。実際、ベクトルは幾何的な側面(長さ、内積、直行性など)
| と線形代数的な側面(独立性、ランク、特異値など)の顕著な2つの側面を持っており、それらは
| 関連しているとともに有用であることが判明しています。そのため、2章、3章では幾何学と線形
| 代数の基礎をおいています。そこでは高次元空間が2次元や3次元の空間における直感とは意外に
| も外れていることがわかります。2章では、その違いを理解するための基礎を説明します。2章で
| は特定のアプリケーションに注目するのではなく、それらをうまく説明するための知的アイデア
| 全体や数学的な基礎を着目しています。3章では行列データを扱うための中心的なツールとして
| 特異値分解(SVD)に着目し、特異値分解のための数学における第一原理とアルゴリズムを説明し
| ます。主成分分析を含めた広く使われる特異値分解の応用技術に触れ、確率密度のような統計を
| 混同した現代のアプリケーションと離散最適化なども詳しく説明する。

| WEBシステムや大規模システムの構成のような空間での決定性の手法は高価になりがちである。
| それに対して、ランダムウォーク(別名マルコフ連鎖)による方法は多くの場合、より効果的で、
| 明らかである。そのような静的な分布による探索はWEB検索から物理シミュレーションのような
| アプリケーションで重要である。ランダムウォークや電線ネットワークを説明するような数学的
| な理論はマルコフ連鎖として、4章の中心となる。

| 過去20年間でコンピュータサイエンスの驚異的な部分は、ドメインに依存しない手法により多様な
| 分野において大成功を納めていることである。機械学習はその印象的な例である。5章では機械学習
| の基礎を説明します。例として与えられた学習データの最適化アルゴリズムと、そのような最適化
| がまだ見ぬ新しいデータに対して、いつまでよいパフォーマンスを出し続けられるかを理解する
| ための理論を説明します。ここには、ヴァプニク・チェルヴォーネンキス次元(VC次元)のような重要
| な計測方法やパーセプトロン、確率的勾配降下法、ブースティング、深層学習のような重要なアル
| ゴリズム、そして正則化と過学習のような重要な概念を含みます。

| アルゴリズムの分野では、古典的なRAMで表現されるデータを問題への入力として想定する。アルゴ  
| リズムはそのデータへ繰り返しアクセスすることができるものとする。これは膨大なデータに関わる
| 問題の上では現実的ではない。ストリーミングモデルとその他、いくつかのモデルはこれに対応する
| ために策定されている。この設定の上でサンプリングは重要な役割を果たす。実際、我々はその場で
| サンプリングしてみる必要がある。6章では、効果的でよいサンプリングを行う方法や効果的なサン
| プリングを行うための統計的推定と線形代数量について学んでいく。

| 5章においては、ラベル付きのトレーニングデータを使った教師あり学習とラベルが付与されていない
| データによる教師なし学習という2つの同等に重要な学習方法に焦点を当てる。教師なし学習における
| 中心的なトピックは、7章で議論されるクラスタリングである。クラスタリングとはデータを類似した
| オブジェクトグループに領域分けする問題として説明される。k-meansアルゴリズムのような基本的な
| クラスタリングの手法について述べた後に、これらを理解するための最新の開発と、多種のクラスタリ
| ング問題を解析するための新しいアルゴリズムや一般的なフレームワークに焦点を当てている。

| WEBシステムやSNSのような大規模な構造の理解するための中心的な話題は、これらの構造において
| 必要不可欠な性質を掴むためのモデルの生成である。最も単純なモデルはエルディシュとレイニーの
| ランダムグラフである。8章でその詳細を述べ、ローカル選択によって生じる構造として巨大連結成分
| のような、特定のグルーバル現象を論証する。また、他のランダムグラフについても述べる。

| 9章では、データから意味を見出すための線形代数的問題に焦点を当てる。特に、トピックモデルと
| 非負行列因子分解に注目する。加えて、よく知られているモデルについて議論して、アルゴリズムや
| モデルの学習エラーと時間に関する証明可能な保証について述べる。これらはグラフィカルモデルや
| 確率伝搬法に基づく。

| 10章では、ランキングと社会選択について議論する。同等に、センサーデータの圧縮のようなスパー
| ス表現問題についても議論を行う。加えて、10章は線形計画問題や半正定値計画問題の簡単な議論を
| 含めている。広範囲のアプリケーションに対する信号表現を行う方法として重要なウェーブレットは
| 基本的な数学的性質とともに、11章で議論を行う。付録には背景知識を含めている。

表記について
------------------------

| 読者を助けるために特別な表記の適用し、それに付随する少々の例外を導入する。
| 小文字はスカラー変数または関数を表し、太字の小文字はベクトルを表す。大文字は行列を表す。
| アルファベットの前半の文字を使用している場合は定数である場合が多い。 :math:`i, j, k` のような中盤の
| アルファベットは総和の添え字に使用する。 :math:`n, m` は整数値の大きさを表し、変数に対してはx, y, z
| を使用する。もし、:math:`A` が行列ならば、その要素を :math:`a_{ij}` とし、その行を :math:`\textbf{a}_i` とする。
| :math:`\textbf{a}_i` がベクトルならば、その要素は :math:`a_{ij}` である。
| 参考文献が数量を伝統的な記号で表しているならば、それに従った記号を使用した。そこでは上記の
| 慣習を無視して記述している。
| ベクトル空間上の点集合を取り、その部分空間で考える時、 :math:`n` を点の個数とし、 :math:`d` を空間の次元
| とし、 :math:`k` を部分空間の次元とする。

| “almost surely”というフレーズは、確率が1に傾向しているという意味である。
| :math:`\textit{ln} n` は自然対数で、 :math:`\textit{log} n` は底が2の対数である。
| 底が10の対数を使う場合は、 :math:`\textit{log}_10 n` を使う。
| 記法の簡略化と読みやすさのために、
| :math:`(E(1-x))^2` を :math:`E^2(1-x)` と略記し、 :math:`E((1-x)^2)` を :math:`E(1-x)^2` と略記する。
| “randomly select”とは、与えられた確率分布から互いに独立な点を複数取ることである。